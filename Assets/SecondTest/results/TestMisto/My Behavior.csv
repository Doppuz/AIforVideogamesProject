Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Policy/Epsilon,Policy/Beta,Is Training
100000,1.4105636,20.926932501670752,-3.1244879,-3.9541016600783574,-3.9541016600783574,2.2871783,0.022654867,0.0002845878,0.1948626,0.004743643,1.0
200000,1.3839896,35.92420814479638,-2.8922353,-3.2045077076051784,-3.2045077076051784,1.033832,0.02459795,0.00025531984,0.1851066,0.00425682,1.0
300000,1.3523878,64.9390243902439,-1.8679911,-1.7563555029455755,-1.7563555029455755,1.2363899,0.024532584,0.00022449507,0.17483166,0.0037441007,1.0
400000,1.3245981,108.61805555555556,-0.72381985,0.42924886852330557,0.42924886852330557,1.3255727,0.024558522,0.0001951762,0.16505872,0.0032564297,1.0
500000,1.3028952,164.1174438687392,0.2673197,3.2058727498293336,3.2058727498293336,1.2788483,0.023841713,0.00016581645,0.15527214,0.0027680793,1.0
600000,1.288717,220.08663366336634,1.0274062,6.0043324957979785,6.0043324957979785,1.2178725,0.023642713,0.00013483447,0.1449448,0.0022527454,1.0
700000,1.277111,293.83737024221455,1.759272,9.691869665594663,9.691869665594663,1.1060557,0.023386396,0.00010540201,0.13513397,0.0017631855,1.0
800000,1.2684925,429.6341463414634,2.5059528,16.4817090709035,16.4817090709035,0.9167355,0.02430286,7.6002805e-05,0.12533423,0.0012741785,1.0
900000,1.2632607,599.1585365853658,3.0365334,24.723008610719553,24.723008610719553,0.83296883,0.02145099,4.507586e-05,0.11502526,0.0007597604,1.0
1000000,1.260888,507.78823529411767,3.1809905,20.640060592115972,20.640060592115972,0.9400296,0.024095973,1.41308465e-05,0.10471024,0.00024504148,1.0
