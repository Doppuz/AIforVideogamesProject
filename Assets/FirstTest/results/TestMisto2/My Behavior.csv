Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Policy/Epsilon,Policy/Beta,Is Training
100000,1.4181293,28.2131498470948,-0.9859263,-3.586494326482092,-3.586494326482092,5.4240656,0.022964863,0.00028457915,0.19485971,0.0047434997,1.0
200000,1.4053309,33.47494707127735,-2.4480672,-3.313479152546858,-3.313479152546858,1.1205812,0.024046605,0.00025529007,0.1850967,0.004256325,1.0
300000,1.3911963,44.975985500679656,-2.3228357,-2.7328499517237703,-2.7328499517237703,1.019017,0.023255635,0.000224426,0.17480865,0.0037429514,1.0
400000,1.3786303,58.69206939281289,-1.8096998,-2.038475711992682,-2.038475711992682,1.112862,0.024038069,0.00019508832,0.16502945,0.003254968,1.0
500000,1.3576754,94.32850241545894,-1.0527552,-0.24111941905555578,-0.24111941905555578,1.2201145,0.023822667,0.00016570406,0.15523466,0.0027662092,1.0
600000,1.3344786,164.34806629834253,-0.028916603,3.2639048261976153,3.2639048261976153,1.1353222,0.025567323,0.00013477882,0.14492624,0.0022518197,1.0
700000,1.3179349,357.62598425196853,1.1583298,13.298820336972634,13.298820336972634,0.8412268,0.022324532,0.000105449675,0.13514988,0.0017639782,1.0
800000,1.3056328,572.8227848101266,2.3414211,25.46297708191449,25.46297708191449,0.56445014,0.02357727,7.606208e-05,0.12535402,0.0012751645,1.0
900000,1.3006377,644.4150943396227,3.3245833,29.57107191865549,29.57107191865549,0.47152,0.022517046,4.5043857e-05,0.11501459,0.0007592281,1.0
1000000,1.2975318,642.6326530612245,3.8329773,29.443838353026404,29.443838353026404,0.5092457,0.023963038,1.4078105e-05,0.10469266,0.00024416417,1.0
