Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Policy/Epsilon,Policy/Beta,Is Training
100000,1.4208337,31.288297172912557,1.5972468,-8.436106470924035,-8.436106470924035,31.952406,0.022113506,0.00029228887,0.19742961,0.004871738,1.0
200000,1.4143286,37.27276279796796,-1.1444932,-8.135859293490649,-8.135859293490649,14.104437,0.022358846,0.0002776422,0.19254738,0.004628114,1.0
300000,1.4039437,38.80688806888069,-1.3880635,-8.059655514834796,-8.059655514834796,37.56698,0.023407158,0.0002622236,0.18740785,0.0043716524,1.0
400000,1.3942733,44.74226804123711,-4.320556,-7.752714115790371,-7.752714115790371,30.364756,0.039302714,0.00024756682,0.18252224,0.004127861,1.0
