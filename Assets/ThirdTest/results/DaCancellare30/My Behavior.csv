Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Policy/Epsilon,Policy/Beta,Is Training
100000,1.4172256,34.59076027646417,0.55320764,-3.2704330219452036,-3.2704330219452036,16.028465,0.025575725,0.00029226937,0.19742312,0.0048714126,1.0
200000,1.4133228,42.51541850220264,-1.2085145,-2.874801718085873,-2.874801718085873,2.339944,0.024581555,0.0002776007,0.19253355,0.0046274243,1.0
300000,1.395547,63.3875088715401,-1.3014358,-1.830780020335042,-1.830780020335042,1.4533696,0.025615405,0.00026217388,0.18739128,0.004370825,1.0
400000,1.3768332,102.92584009269989,-0.40033585,0.15168242664735446,0.15168242664735446,1.375595,0.023821471,0.00024749458,0.18249819,0.0041266587,1.0
500000,1.3638543,161.83037475345168,0.8747336,3.0893496771065676,3.0893496771065676,1.1732283,0.025700048,0.00023281176,0.1776039,0.0038824347,1.0
600000,1.3583653,220.26077586206895,1.4480706,5.992796516418457,5.992796516418457,1.3338187,0.023849444,0.00021738044,0.17246012,0.0036257606,1.0
700000,1.3523122,280.4052287581699,2.1762578,9.031804356809522,9.031804356809522,1.0739634,0.022591846,0.0002019327,0.16731086,0.0033688128,1.0
800000,1.341844,317.1984126984127,2.6733248,10.838736406899253,10.838736406899253,0.9552134,0.022283612,0.00018726979,0.16242322,0.0031249197,1.0
900000,1.3309311,391.9627906976744,2.90066,14.59814111022062,14.59814111022062,0.8431832,0.025423577,0.00017257259,0.1575242,0.0028804569,1.0
1000000,1.322109,508.04761904761904,3.3681216,20.519463182209495,20.519463182209495,0.7346625,0.025265153,0.00015711214,0.15237068,0.0026232973,1.0
