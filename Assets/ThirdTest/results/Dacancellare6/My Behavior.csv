Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Policy/Epsilon,Policy/Beta,Is Training
100000,1.4159322,12.30058273478791,-6.920363,-5.785638331623703,-5.785638331623703,4.7883453,0.024688113,0.00029483036,0.1982768,0.0049140113,1.0
200000,1.399547,5.877225166462835,-5.099008,-5.296050835767852,-5.296050835767852,0.40264502,0.021812866,0.000285066,0.195022,0.0047515975,1.0
300000,1.3877584,2.528062211900489,-4.915186,-4.955266337969919,-4.955266337969919,0.09083308,0.023011778,0.00027480672,0.19160226,0.0045809513,1.0
