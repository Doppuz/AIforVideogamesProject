Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Policy/Epsilon,Policy/Beta,Is Training
100000,1.4194278,35.7594514455152,2.969816,-3.211531319970063,-3.211531319970063,16.525484,0.02401589,0.0002923106,0.19743687,0.0048720995,1.0
200000,1.4114747,42.86983562860951,0.19927953,-2.8573522483015634,-2.8573522483015634,4.3741307,0.023780558,0.00027767496,0.19255832,0.004628661,1.0
300000,1.3994449,51.1419624217119,-1.1328024,-2.443009837941074,-2.443009837941074,1.9421387,0.0244687,0.00026225607,0.18741868,0.004372192,1.0
400000,1.3875554,54.37836322869955,-1.6606046,-2.281081762549054,-2.281081762549054,1.4874262,0.02493303,0.00024759193,0.18253064,0.004128279,1.0
500000,1.3720889,64.34718498659518,-1.4595536,-1.7814888159434001,-1.7814888159434001,1.4300916,0.02358533,0.00023295086,0.17765029,0.003884749,1.0
600000,1.3602849,74.9359487590072,-1.0098411,-1.254999838447571,-1.254999838447571,1.5201849,0.022434933,0.00021752834,0.17250945,0.0036282204,1.0
700000,1.3444912,91.0921435499515,-0.6181178,-0.44539259014259136,-0.44539259014259136,1.4857893,0.02310318,0.00020211004,0.16736999,0.0033717626,1.0
800000,1.330359,110.82346368715083,-0.22143354,0.5411735132419864,0.5411735132419864,1.5036315,0.023784054,0.00018746276,0.16248757,0.0031281295,1.0
900000,1.3177451,111.61658653846153,0.12000259,0.5765346267163108,0.5765346267163108,1.5201164,0.02261791,0.0001727893,0.1575964,0.0028840606,1.0
1000000,1.3061067,149.92436974789916,0.6903397,2.498993778388772,2.498993778388772,1.3338898,0.023503665,0.00015734948,0.15244982,0.0026272456,1.0
1100000,1.2982111,203.1800847457627,1.2306015,5.1590049721426885,5.1590049721426885,1.1870795,0.021901915,0.0001426818,0.14756058,0.002383273,1.0
1200000,1.2867744,201.028,1.3704586,5.051400727272034,5.051400727272034,1.3455803,0.02334429,0.00012796934,0.14265642,0.0021385555,1.0
